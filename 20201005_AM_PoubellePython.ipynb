{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>docsequence</th>\n",
       "      <th>docid</th>\n",
       "      <th>docyear</th>\n",
       "      <th>doctype</th>\n",
       "      <th>allsubject</th>\n",
       "      <th>broadsubj</th>\n",
       "      <th>personalevent</th>\n",
       "      <th>wwritten</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>...</th>\n",
       "      <th>native_occupation.x</th>\n",
       "      <th>north_american_occupation.x</th>\n",
       "      <th>year_immigration.x</th>\n",
       "      <th>cultural_heritage.x</th>\n",
       "      <th>stayed_north_america.x</th>\n",
       "      <th>agewriting</th>\n",
       "      <th>marriagestatus</th>\n",
       "      <th>maternalstatus</th>\n",
       "      <th>author_generation</th>\n",
       "      <th>north_american_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Clergy; Missionaries; Students; Travel; Religi...</td>\n",
       "      <td>Religion; Education; Entertainment and recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ohio; United States; East North Central States...</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italian; European</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Childless</td>\n",
       "      <td>First</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>S1019-D004</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Missionaries; Nuns; Railroad trips; Religious ...</td>\n",
       "      <td>Religion; Entertainment and recreation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kansas City, MO; Missouri; United States; West...</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italian; European</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Childless</td>\n",
       "      <td>First</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>S1019-D005</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Houses; Missionaries; Schools; Stagecoach trav...</td>\n",
       "      <td>Domestic life; Religion; Education; Transporta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinidad, CO; Colorado; United States; Southwe...</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italian; European</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Childless</td>\n",
       "      <td>First</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>S1019-D006</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Churches; Clubs; Discipline; Educational philo...</td>\n",
       "      <td>Religion; Entertainment and recreation; Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinidad, CO; Colorado; United States; Southwe...</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italian; European</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Childless</td>\n",
       "      <td>First</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>S1019-D007</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>Letter</td>\n",
       "      <td>Accidents; Missionaries; Murder; Religious bel...</td>\n",
       "      <td>Transportation; Religion; Law; Education; Ente...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinidad, CO; Colorado; United States; Southwe...</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italian; European</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>Childless</td>\n",
       "      <td>First</td>\n",
       "      <td>Nun; Social worker; Teacher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  docsequence       docid  docyear doctype  \\\n",
       "136         137            2  S1019-D002   1872.0  Letter   \n",
       "137         138            4  S1019-D004   1872.0  Letter   \n",
       "138         139            5  S1019-D005   1872.0  Letter   \n",
       "139         140            6  S1019-D006   1872.0  Letter   \n",
       "140         141            7  S1019-D007   1873.0  Letter   \n",
       "\n",
       "                                            allsubject  \\\n",
       "136  Clergy; Missionaries; Students; Travel; Religi...   \n",
       "137  Missionaries; Nuns; Railroad trips; Religious ...   \n",
       "138  Houses; Missionaries; Schools; Stagecoach trav...   \n",
       "139  Churches; Clubs; Discipline; Educational philo...   \n",
       "140  Accidents; Missionaries; Murder; Religious bel...   \n",
       "\n",
       "                                             broadsubj personalevent  \\\n",
       "136  Religion; Education; Entertainment and recreation           NaN   \n",
       "137             Religion; Entertainment and recreation           NaN   \n",
       "138  Domestic life; Religion; Education; Transporta...           NaN   \n",
       "139  Religion; Entertainment and recreation; Education           NaN   \n",
       "140  Transportation; Religion; Law; Education; Ente...           NaN   \n",
       "\n",
       "                                              wwritten docauthorid  ...  \\\n",
       "136  Ohio; United States; East North Central States...  per0001043  ...   \n",
       "137  Kansas City, MO; Missouri; United States; West...  per0001043  ...   \n",
       "138  Trinidad, CO; Colorado; United States; Southwe...  per0001043  ...   \n",
       "139  Trinidad, CO; Colorado; United States; Southwe...  per0001043  ...   \n",
       "140  Trinidad, CO; Colorado; United States; Southwe...  per0001043  ...   \n",
       "\n",
       "    native_occupation.x  north_american_occupation.x year_immigration.x  \\\n",
       "136                 NaN  Nun; Social worker; Teacher                NaN   \n",
       "137                 NaN  Nun; Social worker; Teacher                NaN   \n",
       "138                 NaN  Nun; Social worker; Teacher                NaN   \n",
       "139                 NaN  Nun; Social worker; Teacher                NaN   \n",
       "140                 NaN  Nun; Social worker; Teacher                NaN   \n",
       "\n",
       "    cultural_heritage.x stayed_north_america.x agewriting marriagestatus  \\\n",
       "136   Italian; European                 Stayed       22.0         Single   \n",
       "137   Italian; European                 Stayed       22.0         Single   \n",
       "138   Italian; European                 Stayed       22.0         Single   \n",
       "139   Italian; European                 Stayed       22.0         Single   \n",
       "140   Italian; European                 Stayed       23.0         Single   \n",
       "\n",
       "     maternalstatus  author_generation    north_american_occupation  \n",
       "136       Childless              First  Nun; Social worker; Teacher  \n",
       "137       Childless              First  Nun; Social worker; Teacher  \n",
       "138       Childless              First  Nun; Social worker; Teacher  \n",
       "139       Childless              First  Nun; Social worker; Teacher  \n",
       "140       Childless              First  Nun; Social worker; Teacher  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Library & Data\n",
    "import pandas as pd \n",
    "df = pd.read_csv(\"20200929_AM_FinalMeta.csv\") \n",
    "\n",
    "# Select cases\n",
    "englishLetters = df.loc[(df['doctype'] == \"Letter\") & (df['language'] == \"English\")]\n",
    "englishLetters[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>doctype</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       docid doctype language\n",
       "count   1073    1073     1073\n",
       "unique  1073       1        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data check shows that doctype and language variables have 1 level and no missing data\n",
    "englishLetters[['docid', 'doctype', 'language']].describe()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S10003</td>\n",
       "      <td>D032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0  S10003  D023\n",
       "1  S10003  D024\n",
       "2  S10003  D025\n",
       "3  S10003  D026\n",
       "4  S10003  D027\n",
       "5  S10003  D028\n",
       "6  S10003  D029\n",
       "7  S10003  D030\n",
       "8  S10003  D031\n",
       "9  S10003  D032"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object (series)\n",
    "# Place into it the values in docid\n",
    "# Split into sourceid (1st element) and docid (2nd element)\n",
    "IDs = pd.Series(df[\"docid\"]).str.split(pat = \"-\", expand=True)\n",
    "IDs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to extract text from HTML\n",
    "for index in range(len(IDs)):\n",
    "    f = open(\"dataNAIL/\" + IDs['Src'].iloc[index] + \".txt\",\"r\", encoding = 'utf-8')\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    doc = soup.find(id=IDs.iloc[index,2])\n",
    "    paras = doc.find_all(\"p\")\n",
    "    letter = []\n",
    "    for para in paras:\n",
    "        letter.append(para.contents[0])\n",
    "    f = open(\"letters/\" + IDs.iloc[index,2] + \".txt\", \"w\")\n",
    "    f.write(str(letter))\n",
    "    f.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to extract text from HTML\n",
    "f = open(\"dataNAIL/\" + IDs.iloc[0,0] + \".txt\",\"r\", encoding = 'utf-8')\n",
    "soup = BeautifulSoup(f, 'html.parser')\n",
    "doc = soup.find(id=IDs.iloc[0,2])\n",
    "letter = []\n",
    "for string in doc.stripped_strings:\n",
    "    letter.append(repr(string))\n",
    "letter = str(letter)\n",
    "letter = letter.replace(\"\\\\\\\\n\", \" \")\n",
    "f = open(\"letters/\" + IDs.iloc[0,2], \"w\")\n",
    "f.write(letter)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to extract text -- this worked best\n",
    "f = open(\"dataNAIL/\" + IDs.iloc[0,0] + \".txt\",\"r\", encoding = 'utf-8')\n",
    "soup = BeautifulSoup(f, 'html.parser')\n",
    "doc = soup.find(id=IDs.iloc[0,2])\n",
    "doc = ''.join(text for text in doc.find_all(text=True) if text.parent.name != \"note\")\n",
    "f = open(\"letters/\" + IDs.iloc[0,2] + \".txt\", \"w\")\n",
    "f.write(doc)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Term1a': 'Term1b', 'Term2a': 'Term2b'}\n"
     ]
    }
   ],
   "source": [
    "#Create dictionary\n",
    "dictionary = {\n",
    "  \"Term1a\": \"Term1b\",\n",
    "    \"Term2a\" : \"Term2b\"\n",
    "}\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through files in a directory\n",
    "# Calculate sentiment\n",
    "for fileid in lettersCorpus.fileids():\n",
    "    text = lettersCorpus.raw(fileid)\n",
    "    sentences = sentenceTokenizer.tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        scores = sentimentAnalyzer.polarity_scores(sentence)\n",
    "        print(sentence)\n",
    "        print(scores)\n",
    "    print(fileid)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary to hold scores.\n",
    "compoundScores = []        \n",
    "for fileid in lettersCorpus.fileids():\n",
    "    text = lettersCorpus.raw(fileid)\n",
    "    sentences = sentenceTokenizer.tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        scores = sentimentAnalyzer.polarity_scores(sentence)\n",
    "        compoundScores.append(scores['compound'])\n",
    "    print(compoundScores)\n",
    "    print(fileid, \"added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate words, sentences, paragraphs in a corpus with PlaintextCorpusReader\n",
    "tokens = lettersCorpus.words()\n",
    "print(len(tokens), \"tokens\")\n",
    "\n",
    "words = [word for word in tokens if word[0].isalpha()]\n",
    "print(len(words), \"words\")\n",
    "\n",
    "print(len(set(words)), \"unique word types\")\n",
    "\n",
    "print(len(lettersCorpus.sents()), \"sentences\")\n",
    "print(len(lettersCorpus.paras()), \"paragraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add stopwords to nltk list\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 'carrother'\n",
    "# python check if value exist in dict using \"in\" & values()\n",
    "if value in id2word.values():\n",
    "    print(f\"Yes, Value: '{value}' exists in dictionary\")\n",
    "else:\n",
    "    print(f\"No, Value: '{value}' does not exists in dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering\n",
    "topic_num_keywords = topic_num_keywords.reindex([1,5,3,10,2,6,8,7,0,4,9])\n",
    "topic_num_keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
